#!/usr/bin/env python
"""
Does some regressions up in this ish.

Usage:
    epi-xbrain-rf [options] <X> <y>

Arguments:
    <X>         Input data to run predictions on (one row per participant)
    <y>         Data to predict (continuous).

Options:
    --model=<model>   LR_L1, SVR, or RFR [default: RFR]
    --nfold=<nfold>   Number of folds for cross validations [default: 10]
    --stratified      Do stratified cross-validation.

DETAILS
    epi-xbrain-rf -h or --help prints this message.
"""

from epitome.docopt import docopt
import numpy as np
from scipy import stats
from scipy.stats import mode
import h5py as h5
import pandas as pd
import pickle
import re
import time
import datetime
import collections
import tables as tb
from math import isnan

import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = (15, 10)
plt.style.use('ggplot')

from sklearn import preprocessing
from sklearn import grid_search
from sklearn.cross_validation import KFold
from sklearn.cross_validation import StratifiedKFold
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error as mse

def pickleIt(my_data,save_path):
    f = open(save_path, 'wb')
    pickle.dump(my_data, f)
    f.close()

def CVLoop(model_clf, hyperparams, X_train, y_train):
    """
    Uses cross validation to do a grid search on the hyperparameter dictionary
    input.
    """
    clf = grid_search.GridSearchCV(model_clf, hyperparams, cv=3,verbose=0)
    clf.fit(X_train, y_train)

    return clf

def fold(X_train, y_train, X_test, y_test, model_clf, hyperparams, i):

    hp_dict = collections.defaultdict(list) #store best hyper-parameters for each fold

    clf = CVLoop(model_clf, hyperparams, X_train, y_train)
    for hp in hyperparams:
        hp_dict[hp].append(clf.best_estimator_.get_params()[hp])

    r_train = stats.pearsonr(clf.predict(X_train), y_train)
    r_test = stats.pearsonr(clf.predict(X_test), y_test)
    R2_train = clf.score(X_train, y_train)
    R2_test = clf.score(X_test, y_test)
    MSE_train = mse(clf.predict(X_train), y_train)
    MSE_test = mse(clf.predict(X_test), y_test)

    # visualization
    plt.scatter(clf.predict(X_test),  y_test)
    plt.savefig('test_predicit_{}.jpg'.format(i))
    plt.close()

    # check feature importance (QC for HC importance)
    # for fid in np.arange(10):
    #     model_clf.fit(X_train[fid],y_train[fid])
    #     feat_imp = model_clf.feature_importances_
    #     print
    #     print 'fid: {} r: {}'.format(fid, zip(*CV_r_valid)[0][fid])
    #     print feat_imp[70:], np.argsort(feat_imp)[70:]

    return {'r_train':r_train,
            'r_test':r_test,
            'R2_train':R2_train,
            'R2_test':R2_test,
            'MSE_train':MSE_train,
            'MSE_test':MSE_test,
            'hp_dict':hp_dict,
            'predicted_fold_score': clf.predict(X_test),
            'actual_fold_scores':y_test}

def main():
    arguments = docopt(__doc__)
    X          = arguments['<X>']
    y          = arguments['<y>']
    model      = arguments['--model']
    nfold      = int(arguments['--nfold'])
    stratified = arguments['--stratified']

    # transforms label values
    # only for classification!!
    #le = preprocessing.LabelEncoder()
    #le.fit(y)
    #y_labels = le.transform(y)

    X = np.genfromtxt(X, delimiter=',')
    y = np.genfromtxt(y, delimiter=',')

    if X.shape[0] != y.shape[0]:
        sys.exit('ERROR: X has {} rows, y has {} rows'.format(X.shape[0], y.shape[0]))

    if stratified:
        print('MSG: using stratified kfold cross-validation')
        kf = StratifiedKFold(y_labels, n_folds=nfold)
    else:
        print('MSG: using kfold cross-validation')
        kf = KFold(len(y), n_folds=nfold)

    if model == 'LR_L1':
        model_clf = Lasso()
        hyperparams = {'alpha':[0.2, 0.1, 0.05, 0.01]}
        scale_data = True
        feat_imp = True
    elif model == 'SVR':
        model_clf = SVR()
        hyperparams = {'kernel':['linear','rbf'], 'C':[1,10,25]}
        scale_data = True
        feat_imp = True
    elif model == 'RFR':
        model_clf = RandomForestRegressor(n_jobs=6)
        hyperparams = {'n_estimators':[10,25,50,100,200],'min_samples_split':[2,4,6,8,10]}
        scale_data = False
        feat_imp = True
    else:
        sys.exit('ERROR: Invalid model type {}'.format(model))

    if scale_data:
        X = preprocessing.scale(X)

    # values stored for each fold
    CV_r_train, CV_r_valid = [], []
    CV_R2_train, CV_R2_valid = [], []
    CV_MSE_train, CV_MSE_valid = [], []
    predicted_CV_scores, actual_CV_scores = [], []
    hp_dict = collections.defaultdict(list)

    # get training and test data for each fold
    i = 1
    for train_index, test_index in kf:
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        print('MSG: fold {}'.format(i))
        results = fold(X_train, y_train, X_test, y_test, model_clf, hyperparams, i)
        i += 1

        CV_r_train.append(results['r_train'])
        CV_r_valid.append(results['r_test'])
        CV_R2_train.append(results['R2_train'])
        CV_R2_valid.append(results['R2_test'])
        CV_MSE_train.append(results['MSE_train'])
        CV_MSE_valid.append(results['MSE_test'])
        predicted_CV_scores.append(results['predicted_fold_score'])
        actual_CV_scores.append(results['actual_fold_scores'])

        for hp in hyperparams:
            hp_dict[hp].append(results['hp_dict'][hp])


    # find out most frequent hyper-params during cross-val
    hp_mode = {}
    for hp in hyperparams:
        hp_mode[hp] = mode(hp_dict[hp])[0][0]

    print('most frequent hp: {}'.format(hp_mode))
    print('CV r   (mean, median, std_err): {:04.2f}, {:04.2f}, {:04.2f}'.format(
           np.mean(zip(*CV_r_valid)[0]), np.median(zip(*CV_r_valid)[0]),stats.sem(zip(*CV_r_valid)[0])))
    print('CV R2  (mean, median, std_err): {:04.2f}, {:04.2f}, {:04.2f}'.format(
           np.mean(CV_R2_valid),         np.median(CV_R2_valid),        stats.sem(CV_R2_valid)))
    print('CV MSE (mean, median, std_err): {:04.2f}, {:04.2f}, {:04.2f}'.format(
           np.mean(CV_MSE_valid),        np.median(CV_MSE_valid),       stats.sem(CV_MSE_valid)))

if __name__ == '__main__':
    main()

