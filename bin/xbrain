#!/usr/bin/env python
"""
xbrain is a tool for relating non-neural scores and MRI data features.

Usage:
    xbrain [options] <database>

Arguments:
    <database>      a .csv file containing MRI data (X) and non-neural data (y)

Options:
    --xcorr=TS             A comma-seperated list of timeseries .csv (2D) predictors to use for cross-brain correlation (inter-subject).
    --connectivity=CONN    A comma-seperated list of timeseries .csv (2D) predictors to use for connectivity (intra-subject).
    --statmaps=STATS       A comma-seperated list of statmap .nii.gz (3D) predictors.
    --roi-mask=MASK        A ROI .nii.gz file with the same dimensions as all input statmaps and the same number of non-zero ROIs as there are unique timeseries.
    --predict=PREDICT      A comma-seperated list of column names in database to predict.
    --k=K                  Number of folds done for outer loop cross-validation [default: 10]
    --pct-variance=PCTVAR  Uses PCA to compress the input features to the number required to retain at least this amount of variance (0-1).
    --target-cutoff=CUTOFF Percentile cutoff to seperate the low and high y score group.
    --target-group=GROUP1  Draw the xbrain template from this group [default: 1]
    --two-template=GROUP2  If defined, features are the difference between target-group and this group. [default: -1]
    --diagnostics          Run diagnostics on input data.
    --debug                Verbose outputs.

DETAILS

The xbrain analysis uses a double-cross validation approach to demonstrate
whether the similarities in neural architecture or activity in the brain (X) is
predictive of non-neural variables of interest (Y). For example, demographics
(age, sex), cognitive scores (IQ, TASIT), or clinical variables (medications
taken, number of hospital visits in the last year).

** outer loop: stratified sample k fold cross validation**

The sample population is split int K distinct folds (e.g., --k=5, or 5 folds).
This requires a large sample (< 70 subjects preferred), but k-fold cross
validation is more robust to major outliers, which are likely in heterogenous
psychiatric populations. Briefly, K-fold cross validation splits the population
into a test set (n/K) and training set (the remainder). For each fold,
cross-brain correlations are calculated for each individual against the
template drawn from the training population only, so there is complete
independence between the test set and the template population. The training data
is used to train a classifier to predict the non-neural variable of interest
using these cross brain correlations. The performance of the model is evaluated
against the test set, and performance measures are averaged across all folds.

**inner loop: hyperparamater cross validation**

3 randomized fold cross validation is done to test all submitted hyperperameters
on splits of the training data. The best model is brought forward for testing.

The grid search for each model is defined in xbrain.stats.classify.

**features**

The primary feature used is cross-brain correlation of fMRI time series, but
this tool will also accept 3D stat maps (i.e., GLM scores, FA). These can be
combined because for each subject, we collapse the timeseries down to a vector
of cross brain correlation values the same length as the number of ROIs.

In order to do this, a mask with nonzero ROIs must be supplied. The number of
nonzero ROIs must be the same as the number of timeseries supplied. The average
statistic from within each ROI will be taken as the feature for that ROI.

During training and testing, the cross brain correlation values and statistic
vectors will be concatenated. One must be careful not to add too many
features into the model, as this can lead to overfitting and poor
generalizability.

xbrain -h or --help prints this message.
"""

import sys, os
import collections
import logging
import random
import string
from copy import copy

import numpy as np
import scipy as sp
from scipy.stats import sem, mode
import pandas as pd
from sklearn.model_selection import StratifiedKFold

from xbrain.docopt import docopt
import xbrain.utils as utils
import xbrain.correlate as corr
import xbrain.stats as stats

logging.basicConfig(level=logging.WARN, format="[%(name)s] %(levelname)s: %(message)s")
logger = logging.getLogger(os.path.basename(__file__))

HOME = os.path.expanduser('~')

def assert_columns(db, columns):
    if not utils.is_column(db, columns):
        logger.error('not all columns {} found'.format(columns))
        sys.exit(1)


def clean(X):
    """
    Replaces nan and inf values in numpy array with zero. If any columns are all
    0, removes them completely.
    """
    X[np.isnan(X)] = 0
    X[np.isinf(X)] = 0
    logger.debug('X matrix has {} bad values (replaced with 0)'.format(np.sum(X == 0)))

    idx_zero = np.where(np.sum(np.abs(X), axis=0) == 0)[0] # find all zero cols

    if len(idx_zero) > 0:
        logger.debug('removing {} columns in X that are all 0'.format(len(idx_zero)))
        idx = np.arange(X.shape[1])
        idx = np.setdiff1d(idx, idx_zeros)
        X = X[:, idx]

    return(X)


def pre_test(db, xcorr, predict, target_cutoff, pct_variance=None):
    """
    A diagnostic pipeline for assessing the inputs to the classifier.

    + Loads X and y. If y has multiple preditors, the top PC is calculated. The
      vector is then thresholded at target_cutoff percentile.
    + If pct_variance is defined, X is reduced using PCA to the number of
      features required to capture that amount of variance (%).
    + Plots a distribution of y, compressed to 1 PC.
    + Saves a .csv with this compressed version of y.
    + Thresholds y, and plots the top 3 PCs of X, with points colored by group
      y. This plot should have no obvious structure.
    + Plots a hierarchical clustering of the (possibly reduced) feature matrix
      X.
    + Uses MDMR to detect relationship between cognitive variables and MRI data.
      Good v scores are ~ 0.1, or 10%.
    """
    logger.info('pre-test: detecting gross relationship between neural and cognitive data')
    X = corr.calc_xbrain(db, db, xcorr)
    X = clean(X)

    # load y, and compress y to a single vector using PCA if required
    y = utils.gather_dv(db, predict)
    if len(y.shape) == 2 and y.shape[0] > 1:
        y_1d = copy(stats.pca_reduce(y.T))
    else:
        y_1d = copy(y)

    # plot the y variable (1d) before generating classes
    stats.distributions(y_1d.T, os.path.join(HOME, 'xbrain_y_dist.pdf'))

    # print the top 3 PCs of X, colour coding by y group (diagnostic for site effects etc)
    stats.pca_plot(X, y_1d, HOME)

    # save the y vector before gathering classes
    np.savetxt(os.path.join(HOME, 'xbrain_y.csv'), y_1d, delimiter=',')

    # convert y into classes, thresholding if required
    if len(np.unique(y_1d)) > 10:
        logger.info('splitting y into two groups: {} percentile cutoff'.format(target_cutoff))
        y_groups = utils.make_dv_groups(y_1d, target_cutoff)
    else:
        y_groups = copy(y_1d)
    y_groups = stats.make_classes(y_groups)

    # compress the number of features X if required
    if pct_variance:
        X = stats.pca_reduce(X, n=X.shape[0], pct=pct_variance)

    # save the X matrix
    np.savetxt(os.path.join(HOME, 'xbrain_X.csv'), X, delimiter=',')

    # plot a hierarchical clustering of the feature matrix X
    clst = stats.cluster(X, HOME)

    # use MDMR to find a relationship between the X matrix and all y predictors
    F, F_null, v = stats.mdmr(y.T, X, method='euclidean')
    thresholds = stats.sig_cutoffs(F_null, two_sided=False)
    if F > thresholds[1]:
        logger.info('pre-test: relationship detected: F={} > {}, variance explained={}'.format(F, thresholds[1], v))
    else:
        logger.warn('pre-test: no relationship detected, variance explained={}'.format(v))

    sys.exit()

def main():
    arguments = docopt(__doc__)
    database      = arguments['<database>']
    xcorr    = arguments['--xcorr']
    connectivity  = arguments['--connectivity']
    statmaps      = arguments['--statmaps']
    predict       = arguments['--predict']
    roi_mask      = arguments['--roi-mask']
    k             = int(arguments['--k'])
    pct_variance  = float(arguments['--pct-variance'])

    print(arguments['--target-cutoff'])
    target_cutoff = float(arguments['--target-cutoff'])
    target_group  = int(arguments['--target-group'])
    two_template  = int(arguments['--two-template'])
    diagnostics   = arguments['--diagnostics']
    debug         = arguments['--debug']

    global HOME

    # init the logger
    logger.info('starting')
    if debug:
        logger.setLevel(logging.DEBUG)

    # check and format inputs
    try:
        db = pd.read_csv(database)
    except:
        logger.error('failed to parse input .csv database {}',format(database))
        sys.exit(1)

    if not utils.is_probability(target_cutoff):
        logger.error('group target_cutoff percentile {} invalid, should be (0-1)'.format(target_cutoff))
        sys.exit(1)

    if pct_variance:
        if not utils.is_probability(pct_variance):
            logger.error('pct variance retained {} invalid, should be (0-1)'.format(pct_variance))

    if two_template > -1:
        if two_template == target_group:
            logger.error('two_template group {} should be different than the target group {}'.format(two_template, target_group))
            sys.exit(1)

    # check all defined database columns
    columns = []
    if statmaps:
        statmaps = statmaps.split(',')
        assert_columns(db, statmaps)
        columns.extend(statmaps)

    if xcorr:
        xcorr = xcorr.split(',')
        assert_columns(db, xcorr)
        columns.extend(xcorr)

    if connectivity:
        connectivity = connectivity.split(',')
        assert_columns(db, connectivity)
        columns.extend(connectivity)

    predict = predict.split(',')
    assert_columns(db, predict)
    columns.extend(predict)

    # reduce data to defined columns
    columns = list(set(columns))
    db = db[columns]
    n_pre = len(db)
    db = db.dropna(axis=0)
    logger.debug('columns in reduced database: {}'.format(columns))
    logger.debug('clean rows in database: {}/{}'.format(len(db), n_pre))

    if diagnostics:
        pre_test(db, xcorr, predict, target_cutoff, pct_variance=pct_variance)

    logger.debug('generating dependent variable vector y')
    y = utils.gather_dv(db, predict)
    if len(y.shape) == 2 and y.shape[0] > 1:
        logger.info('using PCA to reduce {} dvs in y down to 1 component'.format(y.shape[0]))
        y = stats.pca_reduce(y.T)

    # split y into groups if the data is continuous
    if len(np.unique(y)) > 10:
        logger.info('splitting y into two groups: {} percentile cutoff'.format(target_cutoff))
        y = utils.make_dv_groups(y, target_cutoff)
    y = stats.make_classes(y)

    # add a column with the preprocessed y groups
    y_uid = ''.join(random.choice(string.ascii_uppercase) for _ in range(10))
    db[y_uid] = y

    # ensure target_group, two_template group is one of the groups in y
    if target_group not in y:
        logger.error('target group {} not in y: {}'.format(target_group, np.unique(y)))
        sys.exit(1)

    if two_template > -1:
        if two_template not in y:
            logger.error('two template group {} not in y: {}'.format(two_template, np.unique(y)))
            sys.exit(1)

    # stores outputs across folds
    acc_train, acc_test, f1_train, f1_test, auc_train, auc_test = [], [], [], [], [], []
    hp_dict = collections.defaultdict(list)

    # calculate connectivity (can be outside of k-fold since no information is shared between samples)
    if connectivity:
        X_conn = corr.calc_connectivity(db, connectivity)

    # stratified k-fold cross validation: split into train and test sets
    logger.info('Outer Loop: {} fold cross validation'.format(k))
    kf = StratifiedKFold(n_splits=k, shuffle=True)
    for train_idx, test_idx in kf.split(np.zeros(len(y)), y):

        # split the outcome variables into train and test groups
        y_train = y[train_idx]
        y_test = y[test_idx]

        # calculate X_xcorr from a training sample template
        if xcorr:
            logger.debug('xcorr: calculating template 1 (group {})'.format(target_group))
            template_1 = corr.find_template(db.iloc[train_idx], y_uid, xcorr, group=target_group)
            X_xcorr = corr.calc_xbrain(template_1, db, xcorr)

            if two_template > -1:
                logger.debug('xcorr: calculating template 2 (group {})'.format(two_template))
                template_2 = corr.find_template(db.iloc[train_idx], y_uid, xcorr, group=two_template)
                X2_xcorr = corr.calc_xbrain(template_2, db, xcorr)
                logger.debug('xcorr: two template analysis (group {} - group {})'.format(target_group, two_template))
                X_xcorr = X_xcorr - X2_xcorr

        # compose X out of the appropriate matricies
        if xcorr and connectivity:
            X = np.hstack((X_xcorr, X_conn))
        elif connectivity:
            X = X_conn
        elif xcorr:
            X = X_xcorr
        else:
            logger.error('X not defined: no xcorr or connectivity inputs')
            sys.exit(1)

        # remove nonsense values from X
        X = clean(X)

        # split X into test and train groups
        X_train = X[train_idx, :]
        X_test  = X[test_idx, :]

        # if desired, compress the feature matrix X
        if pct_variance:
            X_train, X_test = stats.pca_reduce(X_train, n=X_train.shape[0],
                                                    pct=pct_variance, X2=X_test)

        corr.plot_X(X_train, HOME, title='test-vs-train', X2=X_test)

        # run the classifier
        try:
            results = stats.classify(X_train, X_test, y_train, y_test)
        except Exception as e:
            logger.error(e)
            sys.exit(1)

        # append the results of each fold
        acc_train.append(results['acc_train'])
        acc_test.append(results['acc_test'])
        f1_train.append(results['f1_train'])
        f1_test.append(results['f1_test'])
        auc_train.append(results['auc_train'])
        auc_test.append(results['auc_test'])

        # collects the relevant hyperparameters for the chosen model
        hp_tmp = results['hp_dict']
        for hp in hp_tmp.keys():
            hp_dict[hp].append(hp_tmp[hp])

    # find out most frequent hyperparameters during cross-val
    hp_mode = {}
    for hp in hp_dict.keys():
        hp_mode[hp] = mode(hp_dict[hp])[0][0]
    logger.debug('most frequent hp:\n  {}'.format(hp_mode))

    # final results
    print('train results:\n  acc={}+/-{}\n  f1={}+/-{}\n  auc={}+/-{}'.format(
             np.mean(acc_train), sem(acc_train), np.mean(f1_train), sem(f1_train), np.mean(auc_train), sem(auc_train)))
    print('test results:\n  acc={}+/-{}\n  f1={}+/-{}\n  auc={}+/-{}'.format(
             np.mean(acc_test), sem(acc_test), np.mean(f1_test), sem(f1_test), np.mean(auc_test), sem(auc_test)))

if __name__ == '__main__':
    main()

