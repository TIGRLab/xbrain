#!/usr/bin/env python
"""
xbrain is a tool for relating non-neural scores and MRI data features.

Usage:
    xbrain [options] <database>

Arguments:
    <database>      a .csv file containing MRI data (X) and non-neural data (y)

Options:
    --xcorr=TS             A list of timeseries for intrasubject correlation.
    --connectivity=CONN    A list of timeseries for static connectivity.
    --dynamics=DYNA        A list of timeseries for dynamic connectivity.
    --biotype=BIO          A list of timeseries for biotyping.
    --bion=N               Number of biotypes to find [default: 0].
    --statmaps=STATS       A list of statmaps .nii.gz (3D) predictors.
    --raw=RAW              A list of column names in database as predictors.
    --predict=PREDICT      A list of column names in database to predict.
    --roi-mask=MASK        A ROI NIFTI file.
    --k=K                  Number of cross-validation folds [default: 10]
    --pct-variance=PCTVAR  Compress X using PCA to retain this % of variance (0-1).
    --method=METHOD        One of "multiclass", "target", "ysplit", "anomaly".
    --y-cutoff=CUTOFF      % cutoff to find low and high y group. [default: 0.5]
    --target-group=GROUP1  Draw the xbrain template from this group.
    --two-template=GROUP2  If defined, X is the difference between target-group and this group.
    --output=OUTPUT        A directory to place outputs.
    --diagnostics          Run diagnostics on input data.
    --debug                Verbose outputs.

DETAILS

The xbrain analysis uses a double-cross validation approach to demonstrate
whether the similarities in neural architecture or activity in the brain (X) is
predictive of non-neural variables of interest (y). For example, demographics
(AGE, SEX), cognitive scores (IQ, TASIT), or clinical variables (medications
taken, number of hospital visits in the last year).

** inputs **

<database> is a .csv spreadsheet containing predictor values (y) and paths to
input neuroimaging features (X). e.g.,

SUBJ,  IQ,   AGE,  TS_TASK1,                TS_TASK2
0001,  99,    24,  /path/to/0001_task1.csv, /path/to/0002_task2.csv
0002, 103,    45,  /path/to/0002_task1.csv, /path/to/0002_task2.csv
0003,  89,    32,  /path/to/0002_task1.csv, /path/to/0002_task2.csv

For X, xbrain accepts either 2D timeseries files in .csv format, 3D statmap
files in NIFTI format, raw databse entries (defined on a column wise basis), or
some combination of the above. All inputs can be submitted at comma seperated
lists of inputs, e.g., --xcorr='ts_task1,ts_task2', with 'ts_task1' referring to
a column in <database>.

If a 3D statmap is submitted, a ROI mask of the same dimensions must also be
submitted, and this mask should have the same number of unique ROIs as there are
in the submitted timeseries data. The average value will be taken from each ROI
and added to the feature matrix X.

For y, xbrain accepts either categorical or continuous data. Any column of y
that contains more than 9 unique entries is assumed to be continuous, otherwise
that data is treated as categorical by default.

** methods **

xbrain allows you to perform 4 kinds of classifiction experiments.

"multiclass": takes the predict column as group labels and attempts to build a
n-way classifier. Typically used to distinguish between multiple diagnostic or
treatment groups. xcorr template drawn from --target-group. --two-template can
be any other valid group.

"target": takes the predict column as group labels and sets the target group to
be group 1 (using --target-group), and all other labels to be group 0. Used to
simplify the classification problem (e.g., diagnosis vs. no-diagnosis). xcorr
template drawn from --target-group. If --two-template is defined, it is always
drawn fom group 0.

"ysplit": takes the predict column as a continuous cognitive score and splits it
into a low and high score group. If multiple columns are submitted, uses PCA to
extract the top PC and splits on this variable.  if y-cutoff is defined, splits
at the defined percentile. y-cutoff can be a list of percentiles, in which case
xbrain will test each. If y-cutoff is not defined, a median split is used (0.5).
If y-cutoff is "auto", uses a gaussian fit to guess what percentage of the data
in y are outliers.

"anomaly": takes the input features and attempts to find outliers using the X
data only (neuroimaging features). Then takes the input feature vector y and
looks for any statistical difference between the in-group and outlier group.

** outer loop: stratified sample k fold cross validation**

The sample population is split int K distinct folds (e.g., --k=5, or 5 folds).
This requires a large sample (< 70 subjects preferred), but k-fold cross
validation is more robust to major outliers, which are likely in heterogenous
psychiatric populations. Briefly, K-fold cross validation splits the population
into a test set (n/K) and training set (the remainder). For each fold,
cross-brain correlations are calculated for each individual against the
template drawn from the training population only, so there is complete
independence between the test set and the template population. The training data
is used to train a classifier to predict the non-neural variable of interest
using these cross brain correlations. The performance of the model is evaluated
against the test set, and performance measures are averaged across all folds.

**inner loop: hyperparamater cross validation**

randomized cross validation (3 folds per iteration, 100 iterations) is done to
test all hyperperameters on splits of the training data. The best model is
brought forward for testing. The hyperparameters for each model are defined in
xbrain.stats.classify.

**features**

The primary feature used is cross-brain correlation of fMRI time series, but
this tool will also accept 3D stat maps (i.e., GLM scores, FA). These can be
combined because for each subject, we collapse the timeseries down to a vector
of cross brain correlation values the same length as the number of ROIs.

In order to do this, a mask with nonzero ROIs must be supplied. The number of
nonzero ROIs must be the same as the number of timeseries supplied. The average
statistic from within each ROI will be taken as the feature for that ROI.

During training and testing, the cross brain correlation values and statistic
vectors will be concatenated. One must be careful not to add too many
features into the model, as this can lead to overfitting and poor
generalizability.

xbrain -h or --help prints this message.
"""

import sys, os
import shutil
import collections
import logging
import random
import string

import numpy as np
from scipy.stats import sem, mode
import pandas as pd
from sklearn.model_selection import KFold, StratifiedKFold

from xbrain.docopt import docopt
import xbrain.utils as utils
import xbrain.correlate as corr
import xbrain.stats as stats

logging.basicConfig(level=logging.WARN, format="[%(name)s] %(levelname)s: %(message)s")
logger = logging.getLogger(os.path.basename(__file__))


def parse_results(results):
    """Parses results vector and returns mean & sem for test & train"""
    train_mean = np.mean([i[0] for i in results])
    test_mean = np.mean([i[1] for i in results])
    train_sem = sem([i[0] for i in results])
    test_sem = sem([i[1] for i in results])
    return(train_mean, test_mean, train_sem, test_sem)


def main():
    arguments = docopt(__doc__)
    database      = arguments['<database>']
    xcorr         = arguments['--xcorr']
    connectivity  = arguments['--connectivity']
    dynamics      = arguments['--dynamics']
    biotype       = arguments['--biotype']
    bio_n         = int(arguments['--bion'])
    statmaps      = arguments['--statmaps']
    raw           = arguments['--raw']
    predict       = arguments['--predict']
    roi_mask      = arguments['--roi-mask']
    k             = int(arguments['--k'])
    pct_variance  = arguments['--pct-variance']
    method        = arguments['--method']
    y_cutoff      = arguments['--y-cutoff']
    target_group  = arguments['--target-group']
    two_template  = arguments['--two-template']
    diagnostics   = arguments['--diagnostics']
    debug         = arguments['--debug']
    output        = arguments['--output']

    # logging: debug?
    logger.info('starting')
    if debug:
        logger.setLevel(logging.DEBUG)

    # database: valid csv?
    try:
        db = pd.read_csv(database)
    except:
        logger.error('failed to parse input .csv database {}'.format(database))
        sys.exit(1)

    # output: make directory
    if output:
        if not os.path.exists(output):
            try:
                os.makedirs(output)
            except:
                logger.error('failed to create output directory {}'.format(output))
                sys.exit(1)
    else:
        output = os.path.expanduser('~')

    # backup input database
    shutil.copyfile(database, os.path.join(output, 'xbrain_database.csv'))

    # open information file
    csv_info = open(os.path.join(output, 'xbrain_information.csv'), 'wb')
    csv_info.writelines('xbrain run with the following inputs\n  statmaps={}\n  xcorr={}\n  connectivity={}\n  dynamics={}\n  raw={}\n  predict={}\n'.format(
                         statmaps, xcorr, connectivity, dynamics, raw, predict))

    # gather and reduce database to specified columns
    statmaps = utils.split_columns(statmaps)
    xcorr = utils.split_columns(xcorr)
    connectivity = utils.split_columns(connectivity)
    dynamics = utils.split_columns(dynamics)
    biotype = utils.split_columns(biotype)
    raw = utils.split_columns(raw)
    predict = utils.split_columns(predict)

    columns = []
    for variable in [statmaps, xcorr, connectivity, dynamics, biotype, raw, predict]:
        if variable:
            utils.assert_columns(db, variable)
            columns.extend(variable)
    columns = list(set(columns))
    db = db[columns]
    n_pre = len(db)
    db = db.dropna(axis=0)
    logger.debug('database cols: {}, rows: {}/{}'.format(columns, len(db), n_pre))
    csv_info.writelines('options:\n  n={}\n  k={}\n'.format(len(db), k))

    logger.debug('generating dependent variable vector y')
    y = utils.gather_columns(db, predict)

    # biotype
    if biotype:
        method = 'biotype'
        if bio_n < 2:
            logger.error('biotyping requires at least 2 clusters, but {} requested'.format(bio_n))
            sys.exit(1)

    # method: valid?
    methods = ['multiclass', 'target', 'ysplit', 'anomaly', 'biotype']
    if method not in methods:
        logger.error('method {} invalid, pick from {}'.format(method, methods))
        sys.exit(1)
    csv_info.writelines('  method={}\n'.format(method))

    # y_cutoff: percentile?
    if method == 'ysplit' and y_cutoff != 'auto':
        y_cutoff = float(y_cutoff)
        if not utils.is_probability(y_cutoff):
            logger.error('ysplit: target_cutoff percentile {} invalid, should be [0-1] or "auto"'.format(y_cutoff))
            sys.exit(1)
        csv_info.writelines('  y-cutoff={}\n'.format(y_cutoff))

    # target_group: valid?
    if method == 'ysplit':
        target_group = 1
    if method == 'multiclass' or method == 'target':
        if target_group:
            target_group = int(target_group)
        elif xcorr:
            logger.error('target_group must be defined for "multiclass" and "target" modes when calculating xcorr')
            sys.exit(1)
    if target_group:
        csv_info.writelines('  target-group={}\n'.format(target_group))

    # two_template: valid?
    if method == 'anomaly' and two_template:
        logger.warning('anomaly mode does not allow for two template analysis, ignoring')
        two_template = None
    if two_template:
        two_template = int(two_template)
        if two_template == target_group:
            logger.error('two_template group {} should be different than the target group {}'.format(two_template, target_group))
            sys.exit(1)
        csv_info.writelines('  target-group={}\n'.format(target_group))

    # pct_variance: valid?
    if pct_variance:
        pct_variance = float(pct_variance)
        if not utils.is_probability(pct_variance):
            logger.error('pct variance retained {} invalid, should be (0-1)'.format(pct_variance))
        csv_info.writelines('  pct-variance={}\n'.format(pct_variance))

    csv_info.close()

    if diagnostics:
        # run diagnostics on inputs, no classification (NB: broken)
        stats.pre_test(db, xcorr, predict, y_cutoff, output, pct_variance=pct_variance)

    # preprocess y in prep for classification experiments
    if method != 'biotype':
        if len(y.shape) == 2 and y.shape[1] > 1:
            # compress y to 1d vector, if required (predicted_values)
            logger.info('using PCA to reduce {} dvs in y down to 1 component'.format(y.shape[0]))
            y = stats.pca_reduce(y)

        if method == 'ysplit':
            if y_cutoff == 'auto':
                # automatically determine values that fall outside of the normal
                # range by fitting a gaussian to y and looking for extreme values
                y = stats.find_outliers(y)
            else:
                # split y at a pre-defined percentile
                y = utils.make_dv_groups(y, y_cutoff)

        if method == 'anomaly':
            # automatically determine values that fall outside of the normal
            # range by fitting a gaussian to y and looking for extreme values
            y = stats.find_outliers(y)
        else:
            # split y at a pre-defined percentile
            y = stats.make_classes(y)

        if target_group:
            if target_group not in y:
                logger.error('target_group {} not in y: valid={}'.format(target_group, np.unique(y)))
                sys.exit(1)

        if method == 'target':
            # set y values of the target group to 1, and the rest to 0
            y_tmp = np.zeros(y.shape)
            y_tmp[y == target_group] = 1
            y_tmp[y != target_group] = 0
            y = y_tmp

        # add a column with the preprocessed y groups
        y_preprocessed = ''.join(random.choice(string.ascii_uppercase) for _ in range(10))
        db[y_preprocessed] = y

        # ensure target_group, two_template group is one of the groups in y
        if method != 'anomaly':
            if xcorr and target_group not in y:
                logger.error('target group {} not in y: {}'.format(target_group, np.unique(y)))
                sys.exit(1)

            if two_template:
                if two_template not in y:
                    logger.error('two template group {} not in y: {}'.format(two_template, np.unique(y)))
                    sys.exit(1)

    # stores outputs
    # list of tuples [(train1, test1), (train2, test2), ... (trainN, testN)]
    acc, rec, prec, f1, auc = [], [], [], [], []
    # dict of lists containing the best hyperparameter found for each fold
    hp_dict = collections.defaultdict(list)
    # text files for results
    csv_results = open(os.path.join(output, 'xbrain_results.csv'), 'wb')
    csv_results.writelines('k,accuracy_train,accuracy_test,recall_train,recall_test,precision_train,precision_test,f1_train,f1_test,auc_train,auc_test\n')
    csv_hyper = open(os.path.join(output, 'xbrain_hyperparameters.csv'), 'wb')

    # static connectivity: outside k-fold b/c no info shared between samples
    if connectivity:
        X_conn = corr.calc_connectivity(db, connectivity)

    # raw data: simply append columns to X
    if raw:
        X_raw = utils.gather_columns(db, raw)

    if biotype:
        X_bio = corr.calc_connectivity(db, connectivity)

    # stratified k-fold cross validation: split into train and test sets
    logger.info('Outer Loop: {} fold cross validation'.format(k))

    # for biotyping, we don't know who the groups are yet, so we can't stratify
    if method == 'biotype':
        kf = KFold(n_splits=k, shuffle=True)
    else:
        kf = StratifiedKFold(n_splits=k, shuffle=True)

    count = 1
    for train_idx, test_idx in kf.split(np.zeros(y.shape[0]), y):

        # split the outcome variables into train and test groups
        if method != 'biotype':
            y_train = y[train_idx]
            y_test = y[test_idx]
        else:
            # use CCA, clustering, LDA to find the biotypes for test and train
            y_train, y_test = stats.biotype(X_bio[train_idx, :], X_bio[test_idx, :], y[train_idx, :])
            sys.exit()

        # cross-brain correlations: calculate X_xcorr from a training templates
        if xcorr:

            logger.debug('xcorr: calculating template 1 (group {})'.format(target_group))
            if method == 'anomaly':
                # anomaly mode: use all subjects from training data to create X
                template_1 = corr.find_template(db.iloc[train_idx], y_preprocessed, xcorr)
            else:
                # use subjects from the target group to create X
                template_1 = corr.find_template(db.iloc[train_idx], y_preprocessed, xcorr, group=target_group)
            X_xcorr = corr.calc_xbrain(template_1, db, xcorr)

            if two_template:
                # create a second X from the second target group defined
                logger.debug('xcorr: calculating template 2 (group {})'.format(two_template))
                template_2 = corr.find_template(db.iloc[train_idx], y_preprocessed, xcorr, group=two_template)
                X2_xcorr = corr.calc_xbrain(template_2, db, xcorr)
                logger.info('xcorr: two template analysis (group {} - group {})'.format(target_group, two_template))
                X_xcorr = X_xcorr - X2_xcorr

        # dynamic connectivity: calculate group-wise states from training data
        if dynamics:
            # first, identify states for each group win_len=30, win_step=2
            d_rs = corr.calc_dynamic_connectivity(db, dynamics, 30, 2)
            groups = np.unique(y_train)

            for i, group in enumerate(groups):
                logger.debug('dynamics: calculating states for group {}'.format(group))

                # sub-select the training data from this group
                train_idx_subset = train_idx[np.where(y_train == group)[0]]
                d_rs_group = d_rs[:, :, train_idx_subset]

                # reshape to rois x windows
                n_rois, n_windows, n_subj = d_rs_group.shape
                d_rs_group = d_rs_group.reshape(n_rois, n_windows*n_subj)

                # use k means clustering to compute centroids (rois x states)
                group_states = stats.get_states(d_rs_group, k=5)

                # combine states between groups
                if i == 0:
                    states = group_states
                else:
                    states = np.hstack((states, group_states))

            # now regress each subject against the state vectors
            for subj in np.arange(d_rs.shape[2]):
                coeffs = stats.fit_states(d_rs[:, :, subj], states)
                if subj == 0:
                    X_dynamics = coeffs
                else:
                    X_dynamics = np.vstack((X_dynamics, coeffs))

        # compose X out of the appropriate matricies
        try:
            del X # resets X for each fold
        except:
            pass

        for features in ['X_xcorr', 'X_conn', 'X_dynamics', 'X_raw']:
            if features in vars():
                if 'X' in vars():
                    X = np.hstack((X, eval(features)))
                else:
                    X = eval(features)
        try:
            logger.info('X features size {}'.format(X.shape))
        except:
            logger.error('X not defined: no suitable predictors specified')
            sys.exit(1)

        # remove nonsense values from X
        X = utils.clean(X)

        # split X into test and train groups
        X_train = X[train_idx, :]
        X_test  = X[test_idx, :]

        # if desired, compress the feature matrix X
        if pct_variance:
            X_train, X_test = stats.pca_reduce(X_train, n=X_train.shape[0],
                                                    pct=pct_variance, X2=X_test)

        corr.plot_X(X_train, output, title='test-vs-train', X2=X_test)

        try:
            results = stats.classify(X_train, X_test, y_train, y_test, method)
        except Exception as e:
            logger.error(e)
            sys.exit(1)

        # append the results of each fold
        acc.append(results['accuracy'])
        rec.append(results['recall'])
        prec.append(results['precision'])
        f1.append(results['f1'])
        auc.append(results['auc'])

        csv_results.writelines('{},{},{},{},{},{},{},{},{},{},{}\n'.format(
                                count,
                                results['accuracy'][0],results['accuracy'][1],
                                results['recall'][0], results['recall'][1],
                                results['precision'][0], results['precision'][1],
                                results['f1'][0], results['f1'][1],
                                results['auc'][0], results['auc'][1]))
        count += 1

        # collects the relevant hyperparameters for the chosen model
        hp_tmp = results['hp_dict']
        for hp in hp_tmp.keys():
            hp_dict[hp].append(hp_tmp[hp])
        csv_hyper.writelines(hp_dict)

    # hyperparameters found during inner loop cross validation
    hp_final = {}
    for hp in hp_dict.keys():
        if isinstance(hp_dict[hp][0][0], basestring):
            # categorical hyperparameters, take most frequent
            hp_final[hp] = mode(hp_dict[hp][0])[0][0]
        else:
            # continuous / integet hyperparameters, take median
            hp_final[hp] = np.median(hp_dict[hp][0])
    logger.info('final hyperparameters:\n{}'.format(hp_final))
    csv_hyper.writelines(hp_final)
    csv_hyper.close()

    # final results
    acc_train_mean, acc_test_mean, acc_train_sem, acc_test_sem = parse_results(acc)
    rec_train_mean, rec_test_mean, rec_train_sem, rec_test_sem = parse_results(rec)
    prec_train_mean, prec_test_mean, prec_train_sem, prec_test_sem = parse_results(prec)
    f1_train_mean, f1_test_mean, f1_train_sem, f1_test_sem = parse_results(f1)
    auc_train_mean, auc_test_mean, auc_train_sem, auc_test_sem = parse_results(auc)

    csv_results.writelines('mean,{},{},{},{},{},{},{},{},{},{}\n'.format(
                            acc_train_mean, acc_test_mean,
                            rec_train_mean, rec_test_mean,
                            prec_train_mean, prec_test_mean,
                            f1_train_mean, f1_test_mean,
                            auc_train_mean, auc_test_mean))

    csv_results.writelines('sem,{},{},{},{},{},{},{},{},{},{}'.format(
                            acc_train_sem, acc_test_sem,
                            rec_train_sem, rec_test_sem,
                            prec_train_sem, prec_test_sem,
                            f1_train_sem, f1_test_sem,
                            auc_train_sem, auc_test_sem))
    csv_results.close()

    logger.info('train results:\n  acc={}+/-{}\n  f1={}+/-{}\n  auc={}+/-{}'.format(
             acc_train_mean, acc_train_sem, f1_train_mean, f1_train_sem, auc_train_mean, auc_train_sem))
    logger.info('test results:\n  acc={}+/-{}\n  f1={}+/-{}\n  auc={}+/-{}'.format(
             acc_test_mean, acc_test_sem, f1_test_mean, f1_test_sem, auc_test_mean, auc_test_sem))

if __name__ == '__main__':
    main()

