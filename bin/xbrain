#!/usr/bin/env python
"""
xbrain is a tool for relating non-neural scores and MRI data features.

Usage:
    xbrain [options] <database>

Arguments:
    <database>      a .csv file containing MRI data (X) and non-neural data (y)

Options:
    --xcorr=TS             A comma-seperated list of timeseries .csv (2D) predictors to use for cross-brain correlation (inter-subject).
    --connectivity=CONN    A comma-seperated list of timeseries .csv (2D) predictors to use for connectivity (intra-subject).
    --dynamics=DYNA        A comma-seperated lisr of timeseries .csv (2D) predictors to use for dynamic connectivity (intra-subject).
    --statmaps=STATS       A comma-seperated list of statmap .nii.gz (3D) predictors.
    --predict=PREDICT      A comma-seperated list of column names in database to predict.
    --roi-mask=MASK        A ROI .nii.gz file with the same dimensions as all input statmaps and the same number of non-zero ROIs as there are unique timeseries.
    --k=K                  Number of folds done for outer loop cross-validation [default: 10]
    --pct-variance=PCTVAR  Uses PCA to compress X to retain at least this % of variance (0-1).
    --method=METHOD        One of "multiclass", "target", "ysplit", "anomaly".
    --y-cutoff=CUTOFF      Percentile cutoff to seperate the low and high y score group. Used for ysplit mode. If 'auto', uses a gaussian fit to guess what percentage of the data in y are outliers [default: 0.5]
    --target-group=GROUP1  Draw the xbrain template from this group.
    --two-template=GROUP2  If defined, features are the difference between target-group and this group.
    --diagnostics          Run diagnostics on input data.
    --debug                Verbose outputs.

DETAILS

The xbrain analysis uses a double-cross validation approach to demonstrate
whether the similarities in neural architecture or activity in the brain (X) is
predictive of non-neural variables of interest (Y). For example, demographics
(age, sex), cognitive scores (IQ, TASIT), or clinical variables (medications
taken, number of hospital visits in the last year).

** methods **

xbrain allows you to perform 4 kinds of classifiction experiments.

"multiclass": takes the predict column as group labels and attempts to build a
n-way classifier. Typically used to distinguish between multiple diagnostic or
treatment groups. xcorr template drawn from --target-group. --two-template can
be any other valid group.

"target": takes the predict column as group labels and sets the target group to
be group 1 (using --target-group), and all other labels to be group 0. Used to
simplify the classification problem (e.g., diagnosis vs. no-diagnosis). xcorr
template drawn from --target-group. If --two-template is defined, it is always
drawn fom group 0.

"ysplit": takes the predict column as a continuous cognitive score and splits it
into a low and high score group. If multiple columns are submitted, uses PCA to
extract the top PC and splits on this variable.  if y-cutoff is defined, splits
at the defined percentile. y-cutoff can be a list of percentiles, in which case
xbrain will test each. If y-cutoff is not defined, a median split is used (0.5).

"anomaly": takes the input features and attempts to find outliers using the X
data only (neuroimaging features). Then takes the input feature vector y and
looks for any statistical difference between the in-group and outlier group.

** outer loop: stratified sample k fold cross validation**

The sample population is split int K distinct folds (e.g., --k=5, or 5 folds).
This requires a large sample (< 70 subjects preferred), but k-fold cross
validation is more robust to major outliers, which are likely in heterogenous
psychiatric populations. Briefly, K-fold cross validation splits the population
into a test set (n/K) and training set (the remainder). For each fold,
cross-brain correlations are calculated for each individual against the
template drawn from the training population only, so there is complete
independence between the test set and the template population. The training data
is used to train a classifier to predict the non-neural variable of interest
using these cross brain correlations. The performance of the model is evaluated
against the test set, and performance measures are averaged across all folds.

**inner loop: hyperparamater cross validation**

randomized cross validation (3 folds per iteration, 100 iterations) is done to
test all hyperperameters on splits of the training data. The best model is
brought forward for testing. The hyperparameters for each model are defined in
xbrain.stats.classify.

**features**

The primary feature used is cross-brain correlation of fMRI time series, but
this tool will also accept 3D stat maps (i.e., GLM scores, FA). These can be
combined because for each subject, we collapse the timeseries down to a vector
of cross brain correlation values the same length as the number of ROIs.

In order to do this, a mask with nonzero ROIs must be supplied. The number of
nonzero ROIs must be the same as the number of timeseries supplied. The average
statistic from within each ROI will be taken as the feature for that ROI.

During training and testing, the cross brain correlation values and statistic
vectors will be concatenated. One must be careful not to add too many
features into the model, as this can lead to overfitting and poor
generalizability.

xbrain -h or --help prints this message.
"""

import sys, os
import collections
import logging
import random
import string

import numpy as np
from scipy.stats import sem, mode
import pandas as pd
from sklearn.model_selection import StratifiedKFold

from xbrain.docopt import docopt
import xbrain.utils as utils
import xbrain.correlate as corr
import xbrain.stats as stats

logging.basicConfig(level=logging.WARN, format="[%(name)s] %(levelname)s: %(message)s")
logger = logging.getLogger(os.path.basename(__file__))

HOME = os.path.expanduser('~')


def main():
    arguments = docopt(__doc__)
    database      = arguments['<database>']
    xcorr         = arguments['--xcorr']
    connectivity  = arguments['--connectivity']
    dynamics      = arguments['--dynamics']
    statmaps      = arguments['--statmaps']
    predict       = arguments['--predict']
    roi_mask      = arguments['--roi-mask']
    k             = int(arguments['--k'])
    pct_variance  = arguments['--pct-variance']
    method        = arguments['--method']
    y_cutoff      = arguments['--y-cutoff']
    target_group  = arguments['--target-group']
    two_template  = arguments['--two-template']
    diagnostics   = arguments['--diagnostics']
    debug         = arguments['--debug']

    global HOME

    logger.info('starting')
    if debug:
        logger.setLevel(logging.DEBUG)

    # check and format inputs
    try:
        db = pd.read_csv(database)
    except:
        logger.error('failed to parse input .csv database {}',format(database))
        sys.exit(1)

    if method not in ['multiclass', 'target', 'ysplit', 'anomaly']:
        logger.error('method {} invalid, pick form "multiclass", "target", "ysplit", "anomoly"'.format(method))
        sys.exit(1)

    if method == 'ysplit' and y_cutoff != 'auto':
            y_cutoff = float(y_cutoff)
            if not utils.is_probability(y_cutoff):
                logger.error('ysplit: target_cutoff percentile {} invalid, should be [0-1] or "auto"'.format(y_cutoff))
                sys.exit(1)

    if method == 'ysplit':
        target_group = 1

    if method == 'multiclass' or method == 'target':
        if target_group:
            target_group = int(target_group)
        elif xcorr:
            logger.error('target_group must be defined for "multiclass" and "target" modes when calculating xcorr')
            sys.exit(1)

    if method == 'anomaly' and two_template:
        logger.warning('anomaly mode does not allow for two template analysis, ignoring')
        two_template = None

    if pct_variance:
        if not utils.is_probability(pct_variance):
            logger.error('pct variance retained {} invalid, should be (0-1)'.format(pct_variance))

    if two_template:
        two_template = int(two_template)
        if two_template == target_group:
            logger.error('two_template group {} should be different than the target group {}'.format(two_template, target_group))
            sys.exit(1)

    # gather and reduce to defined database columns
    statmaps = utils.split_columns(statmaps)
    xcorr = utils.split_columns(xcorr)
    connectivity = utils.split_columns(connectivity)
    dynamics = utils.split_columns(dynamics)
    predict = utils.split_columns(predict)

    columns = []
    for variable in [statmaps, xcorr, connectivity, dynamics, predict]:
        if variable:
            utils.assert_columns(db, variable)
            columns.extend(variable)

    columns = list(set(columns))
    db = db[columns]
    n_pre = len(db)
    db = db.dropna(axis=0)
    logger.debug('database cols: {}, rows: {}/{}'.format(columns, len(db), n_pre))

    logger.debug('generating dependent variable vector y')
    y = utils.gather_dv(db, predict)

    # instead of doing any classification experiments, run diagnostics on inputs
    if diagnostics:
        stats.pre_test(db, xcorr, predict, y_cutoff, pct_variance=pct_variance)

    # preprocessing of input y values (predicted values)
    if len(y.shape) == 2 and y.shape[0] > 1:
        logger.info('using PCA to reduce {} dvs in y down to 1 component'.format(y.shape[0]))
        y = stats.pca_reduce(y.T)

    if method == 'ysplit':
        if y_cutoff == 'auto':
            y = stats.find_outliers(y)
        else:
            y = utils.make_dv_groups(y, y_cutoff)

    if method == 'anomaly':
        y = stats.find_outliers(y)
    else:
        y = stats.make_classes(y)

    # add a column with the preprocessed y groups
    y_preprocessed = ''.join(random.choice(string.ascii_uppercase) for _ in range(10))
    db[y_preprocessed] = y

    # ensure target_group, two_template group is one of the groups in y
    if method != 'anomaly':
        if xcorr and target_group not in y:
            logger.error('target group {} not in y: {}'.format(target_group, np.unique(y)))
            sys.exit(1)

        if two_template:
            if two_template not in y:
                logger.error('two template group {} not in y: {}'.format(two_template, np.unique(y)))
                sys.exit(1)

    # stores outputs across folds
    acc_train, acc_test, f1_train, f1_test, auc_train, auc_test = [], [], [], [], [], []
    hp_dict = collections.defaultdict(list)

    # calculate static connectivity (can be outside of k-fold since no
    # information is shared between samples)
    if connectivity:
        X_conn = corr.calc_connectivity(db, connectivity)

    # stratified k-fold cross validation: split into train and test sets
    logger.info('Outer Loop: {} fold cross validation'.format(k))
    kf = StratifiedKFold(n_splits=k, shuffle=True)
    for train_idx, test_idx in kf.split(np.zeros(len(y)), y):

        # split the outcome variables into train and test groups
        y_train = y[train_idx]
        y_test = y[test_idx]

        # cross-brain correlations: calculate X_xcorr from a training sample template
        if xcorr:
            logger.debug('xcorr: calculating template 1 (group {})'.format(target_group))

            if method == 'anomaly':
                template_1 = corr.find_template(db.iloc[train_idx], y_preprocessed, xcorr)
            else:
                template_1 = corr.find_template(db.iloc[train_idx], y_preprocessed, xcorr, group=target_group)

            X_xcorr = corr.calc_xbrain(template_1, db, xcorr)

            if two_template:
                logger.debug('xcorr: calculating template 2 (group {})'.format(two_template))
                template_2 = corr.find_template(db.iloc[train_idx], y_preprocessed, xcorr, group=two_template)
                X2_xcorr = corr.calc_xbrain(template_2, db, xcorr)
                logger.debug('xcorr: two template analysis (group {} - group {})'.format(target_group, two_template))
                X_xcorr = X_xcorr - X2_xcorr

        # dynamic functional connectivity: calculate group-wise states from training sample
        if dynamics:
            # first, identify states for each group
            groups = np.unique(y_train)
            # hard-coded: window length=16, window step size=8
            d_rs = corr.calc_dynamic_connectivity(db, dynamics, 16, 8)

            for i, group in enumerate(groups):
                logger.debug('dynamics: calculating states for group {}'.format(group))

                # sub-select the training data from this group
                train_idx_subset = train_idx[np.where(y_train == group)[0]]
                d_rs_group = d_rs[:, :, train_idx_subset]

                # reshape to rois x windows
                n_rois, n_windows, n_subj = d_rs_group.shape
                d_rs_group = d_rs_group.reshape(n_rois, n_windows*n_subj)

                # use k means clustering to compute centroids (rois x states)
                group_states = stats.get_states(d_rs_group, k=5)

                # combine states between groups
                if i == 0:
                    states = group_states
                else:
                    states = np.hstack((states, group_states))

            # now regress each subject against the state vectors
            for subj in np.arange(d_rs.shape[2]):
                coeffs = stats.fit_states(d_rs[:, :, subj], states)
                if subj == 0:
                    X_dynamics = coeffs
                else:
                    X_dynamics = np.vstack((X_dynamics, coeffs))
                    print(X_dynamics)

        # compose X out of the appropriate matricies
        if xcorr and connectivity and dynamics:
            X = np.hstack((X_xcorr, X_conn, X_dynamics))
        elif xcorr and dynamics:
            X = np.hstack((X_xcorr, X_dynamics))
        elif connectivity and dynamics:
            X = np.hstack((X_conn, X_dynamics))
        elif xcorr and connectivity:
            X = np.hstack((X_xcorr, X_conn))
        elif dynamics:
            X = X_dynamics
        elif connectivity:
            X = X_conn
        elif xcorr:
            X = X_xcorr
        else:
            logger.error('X not defined: need xcorr, connectivity, or dynamics inputs')
            sys.exit(1)

        # remove nonsense values from X
        X = utils.clean(X)

        # split X into test and train groups
        X_train = X[train_idx, :]
        X_test  = X[test_idx, :]

        # if desired, compress the feature matrix X
        if pct_variance:
            X_train, X_test = stats.pca_reduce(X_train, n=X_train.shape[0],
                                                    pct=pct_variance, X2=X_test)

        corr.plot_X(X_train, HOME, title='test-vs-train', X2=X_test)

        try:
            results = stats.classify(X_train, X_test, y_train, y_test, method)
        except Exception as e:
            logger.error(e)
            sys.exit(1)

        # append the results of each fold
        acc_train.append(results['acc_train'])
        acc_test.append(results['acc_test'])
        f1_train.append(results['f1_train'])
        f1_test.append(results['f1_test'])
        auc_train.append(results['auc_train'])
        auc_test.append(results['auc_test'])

        # collects the relevant hyperparameters for the chosen model
        hp_tmp = results['hp_dict']
        for hp in hp_tmp.keys():
            hp_dict[hp].append(hp_tmp[hp])

    # find out most frequent hyperparameters during cross-val
    hp_final = {}
    for hp in hp_dict.keys():
        if isinstance(hp_dict[hp][0][0], basestring):
            # categorical hyperparameters, take most frequent
            hp_final[hp] = mode(hp_dict[hp][0])[0][0]
        else:
            # continuous / integet hyperparameters, take median
            hp_final[hp] = np.median(hp_dict[hp][0])
    logger.debug('final hyperparameters:\n{}'.format(hp_final))

    # final results
    logger.info('train results:\n  acc={}+/-{}\n  f1={}+/-{}\n  auc={}+/-{}'.format(
             np.mean(acc_train), sem(acc_train), np.mean(f1_train), sem(f1_train), np.mean(auc_train), sem(auc_train)))
    logger.info('test results:\n  acc={}+/-{}\n  f1={}+/-{}\n  auc={}+/-{}'.format(
             np.mean(acc_test), sem(acc_test), np.mean(f1_test), sem(f1_test), np.mean(auc_test), sem(auc_test)))

if __name__ == '__main__':
    main()

